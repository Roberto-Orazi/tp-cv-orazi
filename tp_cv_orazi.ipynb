{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto de Visión por Computadora - Etapas 1 a 4\n",
    "\n",
    "Este notebook consolida todo el código del proyecto, incluyendo utilidades y scripts de cada etapa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-cpu gradio ultralytics onnx onnxruntime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Roberto-Orazi/tp-cv-orazi.git\n",
    "!ln -s tp-cv-orazi/dataset dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import cv2\n",
    "import faiss\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import gradio as gr\n",
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "import torch.quantization\n",
    "\n",
    "# Configuración\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilidades (Utils)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, dataset_type=None, transform=None):\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        if dataset_type:\n",
    "            self.data = df[df['data set'] == dataset_type].reset_index(drop=True)\n",
    "        else:\n",
    "            self.data = df\n",
    "\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(sorted(df['labels'].unique()))}\n",
    "        self.idx_to_label = {idx: label for label, idx in self.label_to_idx.items()}\n",
    "        self.num_classes = len(self.label_to_idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.root_dir / self.data.iloc[idx]['filepaths']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.data.iloc[idx]['labels']\n",
    "        label_idx = self.label_to_idx[label]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label_idx, str(img_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### models.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet18(num_classes, pretrained=True):\n",
    "    if pretrained:\n",
    "        model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    else:\n",
    "        model = models.resnet18(weights=None)\n",
    "\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def get_resnet50(num_classes, pretrained=True):\n",
    "    if pretrained:\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "    else:\n",
    "        model = models.resnet50(weights=None)\n",
    "\n",
    "    model = nn.Sequential(*list(model.children())[:-1])\n",
    "    return model\n",
    "\n",
    "def get_feature_extractor(model_name='resnet50'):\n",
    "    if model_name == 'resnet50':\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        model = nn.Sequential(*list(model.children())[:-1])\n",
    "    elif model_name == 'resnet18':\n",
    "        model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        model = nn.Sequential(*list(model.children())[:-1])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transforms.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def get_val_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metrics.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(relevances, k):\n",
    "    relevances = np.array(relevances)[:k]\n",
    "    return np.sum(relevances / np.log2(np.arange(2, len(relevances) + 2)))\n",
    "\n",
    "def ndcg_at_k(relevances, k):\n",
    "    dcg = dcg_at_k(relevances, k)\n",
    "    ideal_relevances = sorted(relevances, reverse=True)\n",
    "    idcg = dcg_at_k(ideal_relevances, k)\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "def calculate_metrics_per_class(y_true, y_pred, class_idx):\n",
    "    tp = np.sum((y_true == class_idx) & (y_pred == class_idx))\n",
    "    fp = np.sum((y_true != class_idx) & (y_pred == class_idx))\n",
    "    fn = np.sum((y_true == class_idx) & (y_pred != class_idx))\n",
    "    tn = np.sum((y_true != class_idx) & (y_pred != class_idx))\n",
    "\n",
    "    sensibilidad = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    especificidad = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    exactitud = (tp + tn) / (tp + tn + fp + fn)\n",
    "    f1 = 2 * (precision * sensibilidad) / (precision + sensibilidad) if (precision + sensibilidad) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'fn': fn,\n",
    "        'tn': tn,\n",
    "        'sensibilidad': sensibilidad,\n",
    "        'especificidad': especificidad,\n",
    "        'precision': precision,\n",
    "        'exactitud': exactitud,\n",
    "        'f1': f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 1: Extracción de Embeddings y Buscador\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extraer_embeddings.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando: {device}\")\n",
    "\n",
    "transform = get_val_transform()\n",
    "model = get_feature_extractor('resnet50')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "if not os.path.exists('embeddings_data.pkl'):\n",
    "    print(\"Extrayendo embeddings del dataset...\")\n",
    "    dataset = DogDataset('dataset/dogs.csv', 'dataset', transform=transform)\n",
    "    # OPTIMIZADO PARA COLAB: Batch size aumentado\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    image_paths = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, lbls, paths) in enumerate(dataloader):\n",
    "            if i % 20 == 0:\n",
    "                print(f\"Procesando batch {i}/{len(dataloader)}\")\n",
    "\n",
    "            images = images.to(device)\n",
    "            features = model(images)\n",
    "            features = features.squeeze().cpu().numpy()\n",
    "\n",
    "            if len(features.shape) == 1:\n",
    "                features = features.reshape(1, -1)\n",
    "\n",
    "            embeddings.append(features)\n",
    "            labels.extend(lbls.cpu().numpy())\n",
    "            image_paths.extend(paths)\n",
    "\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "\n",
    "    faiss.normalize_L2(embeddings)\n",
    "\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatIP(dimension)\n",
    "    index.add(embeddings)\n",
    "\n",
    "    print(f\"Indice creado con {index.ntotal} vectores\")\n",
    "\n",
    "    dataset_labels = [dataset.idx_to_label[idx] for idx in labels]\n",
    "\n",
    "    print(\"Guardando embeddings...\")\n",
    "    with open('embeddings_data.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'index': index,\n",
    "            'labels': dataset_labels,\n",
    "            'image_paths': image_paths\n",
    "        }, f)\n",
    "    print(\"Embeddings guardados en embeddings_data.pkl\")\n",
    "else:\n",
    "    print(\"Cargando embeddings previamente guardados...\")\n",
    "    with open('embeddings_data.pkl', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        index = data['index']\n",
    "        labels = data['labels']\n",
    "        image_paths = data['image_paths']\n",
    "    print(f\"Indice cargado con {index.ntotal} vectores\")\n",
    "\n",
    "print(\"\\nExtraccion de embeddings completada!\")\n",
    "print(\"Usa 'python app_etapa1.py' para lanzar la aplicacion Gradio\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluar_ndcg.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando: {device}\")\n",
    "\n",
    "transform = get_val_transform()\n",
    "model = get_feature_extractor('resnet50')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Cargando embeddings...\")\n",
    "with open('embeddings_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    index = data['index']\n",
    "    labels = data['labels']\n",
    "    image_paths = data['image_paths']\n",
    "\n",
    "print(f\"Indice cargado con {index.ntotal} vectores\")\n",
    "\n",
    "def search_similar_images(query_image, k=10):\n",
    "    img = Image.open(query_image).convert('RGB')\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        query_embedding = model(img_tensor)\n",
    "        query_embedding = query_embedding.squeeze().cpu().numpy().reshape(1, -1)\n",
    "\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "    similar_images = []\n",
    "    similar_labels = []\n",
    "\n",
    "    for idx in indices[0]:\n",
    "        similar_images.append(image_paths[idx])\n",
    "        similar_labels.append(labels[idx])\n",
    "\n",
    "    breed_counts = Counter(similar_labels)\n",
    "    predicted_breed = breed_counts.most_common(1)[0][0]\n",
    "\n",
    "    return similar_images, similar_labels, predicted_breed\n",
    "\n",
    "print(\"\\nPreparando conjunto de prueba...\")\n",
    "df = pd.read_csv('dataset/dogs.csv')\n",
    "test_df = df[df['data set'] == 'test']\n",
    "\n",
    "breed_groups = test_df.groupby('labels')\n",
    "test_samples = []\n",
    "\n",
    "# OPTIMIZADO PARA COLAB: Reducido de 5 a 2 muestras por raza\n",
    "for breed, group in breed_groups:\n",
    "    samples = group.sample(min(2, len(group)))\n",
    "    test_samples.extend(samples['filepaths'].tolist())\n",
    "\n",
    "print(f\"Conjunto de prueba: {len(test_samples)} imagenes\")\n",
    "\n",
    "print(\"\\nCalculando NDCG@10...\")\n",
    "ndcg_scores = []\n",
    "accuracy = 0\n",
    "\n",
    "for i, test_path in enumerate(test_samples):\n",
    "    if i % 20 == 0:\n",
    "        print(f\"Evaluando imagen {i}/{len(test_samples)}\")\n",
    "\n",
    "    full_path = Path('dataset') / test_path\n",
    "    true_label = df[df['filepaths'] == test_path]['labels'].values[0]\n",
    "\n",
    "    similar_images, similar_labels, predicted_breed = search_similar_images(str(full_path), k=10)\n",
    "\n",
    "    if predicted_breed == true_label:\n",
    "        accuracy += 1\n",
    "\n",
    "    relevances = [1 if label == true_label else 0 for label in similar_labels]\n",
    "    ndcg = ndcg_at_k(relevances, 10)\n",
    "    ndcg_scores.append(ndcg)\n",
    "\n",
    "avg_ndcg = np.mean(ndcg_scores)\n",
    "accuracy_pct = (accuracy / len(test_samples)) * 100\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"RESULTADOS DE EVALUACION\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"NDCG@10 promedio: {avg_ndcg:.4f}\")\n",
    "print(f\"Accuracy: {accuracy_pct:.2f}% ({accuracy}/{len(test_samples)})\")\n",
    "print(f\"{'='*50}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### app_etapa1.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando: {device}\")\n",
    "\n",
    "transform = get_val_transform()\n",
    "model = get_feature_extractor('resnet50')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Cargando embeddings...\")\n",
    "with open('embeddings_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    index = data['index']\n",
    "    labels = data['labels']\n",
    "    image_paths = data['image_paths']\n",
    "\n",
    "print(f\"Indice cargado con {index.ntotal} vectores\")\n",
    "\n",
    "def search_similar_images(query_image, k=10):\n",
    "    img = Image.open(query_image).convert('RGB')\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        query_embedding = model(img_tensor)\n",
    "        query_embedding = query_embedding.squeeze().cpu().numpy().reshape(1, -1)\n",
    "\n",
    "    faiss.normalize_L2(query_embedding)\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "    similar_images = []\n",
    "    similar_labels = []\n",
    "\n",
    "    for idx in indices[0]:\n",
    "        similar_images.append(image_paths[idx])\n",
    "        similar_labels.append(labels[idx])\n",
    "\n",
    "    breed_counts = Counter(similar_labels)\n",
    "    predicted_breed = breed_counts.most_common(1)[0][0]\n",
    "\n",
    "    return similar_images, similar_labels, predicted_breed\n",
    "\n",
    "def gradio_search(image):\n",
    "    if image is None:\n",
    "        return \"Por favor sube una imagen\", []\n",
    "\n",
    "    try:\n",
    "        similar_images, similar_labels, predicted_breed = search_similar_images(image, k=10)\n",
    "        result_text = f\"Raza predicha: {predicted_breed}\"\n",
    "\n",
    "        gallery_images = []\n",
    "        for img_path, label in zip(similar_images, similar_labels):\n",
    "            gallery_images.append((img_path, label))\n",
    "\n",
    "        return result_text, gallery_images\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\", []\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Etapa 1: Buscador de Razas por Similitud\")\n",
    "    gr.Markdown(\"Modelo: **ResNet50** pre-entrenado (ImageNet)\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            input_image = gr.Image(type=\"filepath\", label=\"Subir imagen\")\n",
    "            search_btn = gr.Button(\"Buscar\")\n",
    "\n",
    "        with gr.Column():\n",
    "            result_text = gr.Textbox(label=\"Resultado\")\n",
    "\n",
    "    gallery = gr.Gallery(label=\"Imagenes similares\", columns=5)\n",
    "\n",
    "    search_btn.click(gradio_search, inputs=input_image, outputs=[result_text, gallery])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nLanzando aplicacion Gradio - Etapa 1...\")\n",
    "    demo.launch(share=False, server_name=\"127.0.0.1\", server_port=7860)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 2: Entrenamiento y Evaluación (ResNet18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### entrenar_resnet18.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando: {device}\")\n",
    "\n",
    "print(\"Cargando datasets...\")\n",
    "train_dataset = DogDataset('dataset/dogs.csv', 'dataset', 'train', transform=get_train_transform())\n",
    "val_dataset = DogDataset('dataset/dogs.csv', 'dataset', 'valid', transform=get_val_transform())\n",
    "test_dataset = DogDataset('dataset/dogs.csv', 'dataset', 'test', transform=get_val_transform())\n",
    "\n",
    "num_classes = train_dataset.num_classes\n",
    "print(f\"Numero de clases: {num_classes}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "print(\"\\nCreando modelo ResNet18...\")\n",
    "model = get_resnet18(num_classes, pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels, _ in tqdm(loader, desc=\"Entrenando\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in tqdm(loader, desc=\"Validando\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "num_epochs = 5\n",
    "best_val_acc = 0.0\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "\n",
    "print(f\"\\nIniciando entrenamiento por {num_epochs} epochs...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'resnet18_best.pth')\n",
    "        print(f\"Mejor modelo guardado con Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "print(\"\\nGraficando resultados...\")\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(train_losses, label='Train Loss')\n",
    "ax1.plot(val_losses, label='Val Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.set_title('Loss durante entrenamiento')\n",
    "\n",
    "ax2.plot(train_accs, label='Train Acc')\n",
    "ax2.plot(val_accs, label='Val Acc')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.legend()\n",
    "ax2.set_title('Accuracy durante entrenamiento')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves.png')\n",
    "print(\"Curvas guardadas en training_curves.png\")\n",
    "\n",
    "print(\"\\nCargando mejor modelo para evaluacion en test...\")\n",
    "model.load_state_dict(torch.load('resnet18_best.pth'))\n",
    "\n",
    "print(\"Evaluando en conjunto de test...\")\n",
    "test_loss, test_acc = validate(model, test_loader, criterion)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "print(\"\\nEntrenamiento completado!\")\n",
    "print(f\"Mejor Val Acc: {best_val_acc:.2f}%\")\n",
    "print(f\"Test Acc: {test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extraer_embeddings_resnet18.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando: {device}\")\n",
    "\n",
    "transform = get_val_transform()\n",
    "\n",
    "print(\"Cargando modelo ResNet18 entrenado...\")\n",
    "dataset = DogDataset('dataset/dogs.csv', 'dataset', transform=transform)\n",
    "num_classes = dataset.num_classes\n",
    "\n",
    "model = get_resnet18(num_classes, pretrained=False)\n",
    "model.load_state_dict(torch.load('resnet18_best.pth', map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Extrayendo embeddings con ResNet18...\")\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "embeddings = []\n",
    "labels = []\n",
    "image_paths = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (images, lbls, paths) in enumerate(dataloader):\n",
    "        if i % 20 == 0:\n",
    "            print(f\"Procesando batch {i}/{len(dataloader)}\")\n",
    "\n",
    "        images = images.to(device)\n",
    "\n",
    "        features = model.conv1(images)\n",
    "        features = model.bn1(features)\n",
    "        features = model.relu(features)\n",
    "        features = model.maxpool(features)\n",
    "        features = model.layer1(features)\n",
    "        features = model.layer2(features)\n",
    "        features = model.layer3(features)\n",
    "        features = model.layer4(features)\n",
    "        features = model.avgpool(features)\n",
    "        features = features.squeeze().cpu().numpy()\n",
    "\n",
    "        if len(features.shape) == 1:\n",
    "            features = features.reshape(1, -1)\n",
    "\n",
    "        embeddings.append(features)\n",
    "        labels.extend(lbls.cpu().numpy())\n",
    "        image_paths.extend(paths)\n",
    "\n",
    "embeddings = np.vstack(embeddings)\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "\n",
    "faiss.normalize_L2(embeddings)\n",
    "\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "print(f\"Indice creado con {index.ntotal} vectores\")\n",
    "\n",
    "dataset_labels = [dataset.idx_to_label[idx] for idx in labels]\n",
    "\n",
    "print(\"Guardando embeddings...\")\n",
    "with open('embeddings_resnet18.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'index': index,\n",
    "        'labels': dataset_labels,\n",
    "        'image_paths': image_paths\n",
    "    }, f)\n",
    "\n",
    "print(\"Embeddings de ResNet18 guardados en embeddings_resnet18.pkl\")\n",
    "print(\"Ahora podes usar 'python app_etapa2.py' para probar ambos modelos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluar_metricas.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando: {device}\")\n",
    "\n",
    "print(\"Cargando dataset de test...\")\n",
    "test_dataset = DogDataset('dataset/dogs.csv', 'dataset', 'test', transform=get_val_transform())\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "num_classes = test_dataset.num_classes\n",
    "print(f\"Numero de clases: {num_classes}\")\n",
    "\n",
    "print(\"\\nCargando modelo ResNet18...\")\n",
    "model = get_resnet18(num_classes, pretrained=False)\n",
    "model.load_state_dict(torch.load('resnet18_best.pth'))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"\\nRealizando predicciones en conjunto de test...\")\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, _ in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = outputs.max(1)\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "accuracy = 100. * np.sum(all_preds == all_labels) / len(all_labels)\n",
    "print(f\"\\nAccuracy en test: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\nCalculando metricas detalladas...\")\n",
    "\n",
    "unique_labels = np.unique(np.concatenate([all_labels, all_preds]))\n",
    "target_names = [test_dataset.idx_to_label[i] for i in unique_labels]\n",
    "\n",
    "report = classification_report(\n",
    "    all_labels,\n",
    "    all_preds,\n",
    "    labels=unique_labels,\n",
    "    target_names=target_names,\n",
    "    output_dict=True,\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METRICAS POR CLASE (primeras 10 razas)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "metrics_df = pd.DataFrame(report).transpose()\n",
    "print(metrics_df.head(10).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METRICAS GLOBALES\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Accuracy:        {report['accuracy']:.4f}\")\n",
    "print(f\"Macro Avg:\")\n",
    "print(f\"  Precision:     {report['macro avg']['precision']:.4f}\")\n",
    "print(f\"  Recall:        {report['macro avg']['recall']:.4f}\")\n",
    "print(f\"  F1-Score:      {report['macro avg']['f1-score']:.4f}\")\n",
    "print(f\"Weighted Avg:\")\n",
    "print(f\"  Precision:     {report['weighted avg']['precision']:.4f}\")\n",
    "print(f\"  Recall:        {report['weighted avg']['recall']:.4f}\")\n",
    "print(f\"  F1-Score:      {report['weighted avg']['f1-score']:.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "metrics_df.to_csv('metricas_detalladas.csv')\n",
    "print(\"\\nMetricas guardadas en metricas_detalladas.csv\")\n",
    "\n",
    "print(\"\\nGenerando matriz de confusion...\")\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(cm, annot=False, fmt='d', cmap='Blues',\n",
    "            xticklabels=target_names, yticklabels=target_names)\n",
    "plt.xlabel('Prediccion')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusion - ResNet18')\n",
    "plt.xticks(rotation=90, ha='right', fontsize=8)\n",
    "plt.yticks(rotation=0, fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=150)\n",
    "print(\"Matriz de confusion guardada en confusion_matrix.png\")\n",
    "\n",
    "print(\"\\nCalculando metricas detalladas por clase...\")\n",
    "\n",
    "for i, class_idx in enumerate(unique_labels[:5]):\n",
    "    class_name = test_dataset.idx_to_label[class_idx]\n",
    "    metrics = calculate_metrics_per_class(all_labels, all_preds, class_idx)\n",
    "\n",
    "    print(f\"\\n{class_name}:\")\n",
    "    print(f\"  TP={metrics['tp']}, FP={metrics['fp']}, FN={metrics['fn']}, TN={metrics['tn']}\")\n",
    "    print(f\"  Sensibilidad (Recall):    {metrics['sensibilidad']:.4f}\")\n",
    "    print(f\"  Especificidad:            {metrics['especificidad']:.4f}\")\n",
    "    print(f\"  Precision:                {metrics['precision']:.4f}\")\n",
    "    print(f\"  Exactitud (Accuracy):     {metrics['exactitud']:.4f}\")\n",
    "    print(f\"  F1-Score:                 {metrics['f1']:.4f}\")\n",
    "\n",
    "print(\"\\nEvaluacion completada!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### app_etapa2.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando: {device}\")\n",
    "\n",
    "transform = get_val_transform()\n",
    "\n",
    "print(\"Cargando modelos...\")\n",
    "\n",
    "model_resnet50 = get_feature_extractor('resnet50')\n",
    "model_resnet50 = model_resnet50.to(device)\n",
    "model_resnet50.eval()\n",
    "\n",
    "csv_file = 'dataset/dogs.csv'\n",
    "temp_dataset = DogDataset(csv_file, 'dataset', 'train', transform=transform)\n",
    "num_classes = temp_dataset.num_classes\n",
    "\n",
    "model_resnet18 = get_resnet18(num_classes, pretrained=False)\n",
    "if os.path.exists('resnet18_best.pth'):\n",
    "    model_resnet18.load_state_dict(torch.load('resnet18_best.pth', map_location=device))\n",
    "    model_resnet18 = model_resnet18.to(device)\n",
    "    model_resnet18.eval()\n",
    "    print(\"ResNet18 entrenado cargado\")\n",
    "else:\n",
    "    model_resnet18 = None\n",
    "    print(\"ResNet18 no encontrado. Ejecuta 'python entrenar_resnet18.py' primero\")\n",
    "\n",
    "print(\"Cargando embeddings ResNet50...\")\n",
    "embeddings_path_50 = 'etapa-1/embeddings_data.pkl'\n",
    "if os.path.exists(embeddings_path_50):\n",
    "    with open(embeddings_path_50, 'rb') as f:\n",
    "        data_50 = pickle.load(f)\n",
    "        index_50 = data_50['index']\n",
    "        labels_50 = data_50['labels']\n",
    "        image_paths_50 = data_50['image_paths']\n",
    "    print(f\"Embeddings ResNet50 cargados: {index_50.ntotal} vectores\")\n",
    "else:\n",
    "    index_50 = None\n",
    "    print(\"Embeddings ResNet50 no encontrados\")\n",
    "\n",
    "embeddings_path_18 = 'embeddings_resnet18.pkl'\n",
    "if os.path.exists(embeddings_path_18):\n",
    "    with open(embeddings_path_18, 'rb') as f:\n",
    "        data_18 = pickle.load(f)\n",
    "        index_18 = data_18['index']\n",
    "        labels_18 = data_18['labels']\n",
    "        image_paths_18 = data_18['image_paths']\n",
    "    print(f\"Embeddings ResNet18 cargados: {index_18.ntotal} vectores\")\n",
    "else:\n",
    "    index_18 = None\n",
    "    print(\"Embeddings ResNet18 no encontrados. Se generaran al buscar\")\n",
    "\n",
    "def extract_features_resnet18(image_path):\n",
    "    if model_resnet18 is None:\n",
    "        return None\n",
    "\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        features = model_resnet18.conv1(img_tensor)\n",
    "        features = model_resnet18.bn1(features)\n",
    "        features = model_resnet18.relu(features)\n",
    "        features = model_resnet18.maxpool(features)\n",
    "        features = model_resnet18.layer1(features)\n",
    "        features = model_resnet18.layer2(features)\n",
    "        features = model_resnet18.layer3(features)\n",
    "        features = model_resnet18.layer4(features)\n",
    "        features = model_resnet18.avgpool(features)\n",
    "        features = features.squeeze().cpu().numpy().reshape(1, -1)\n",
    "\n",
    "    return features\n",
    "\n",
    "def search_similar_images(query_image, model_name, k=10):\n",
    "    if model_name == \"ResNet50 (Pre-entrenado)\":\n",
    "        if index_50 is None:\n",
    "            return [], [], \"Error: Embeddings ResNet50 no encontrados\"\n",
    "\n",
    "        img = Image.open(query_image).convert('RGB')\n",
    "        img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            query_embedding = model_resnet50(img_tensor)\n",
    "            query_embedding = query_embedding.squeeze().cpu().numpy().reshape(1, -1)\n",
    "\n",
    "        faiss.normalize_L2(query_embedding)\n",
    "        distances, indices = index_50.search(query_embedding, k)\n",
    "\n",
    "        similar_images = [image_paths_50[idx] for idx in indices[0]]\n",
    "        similar_labels = [labels_50[idx] for idx in indices[0]]\n",
    "\n",
    "    elif model_name == \"ResNet18 (Fine-tuned)\":\n",
    "        if model_resnet18 is None:\n",
    "            return [], [], \"Error: ResNet18 no encontrado\"\n",
    "\n",
    "        if index_18 is not None:\n",
    "            query_features = extract_features_resnet18(query_image)\n",
    "            faiss.normalize_L2(query_features)\n",
    "            distances, indices = index_18.search(query_features, k)\n",
    "\n",
    "            similar_images = [image_paths_18[idx] for idx in indices[0]]\n",
    "            similar_labels = [labels_18[idx] for idx in indices[0]]\n",
    "        else:\n",
    "            return [], [], \"Error: Embeddings ResNet18 no encontrados\"\n",
    "\n",
    "    else:\n",
    "        return [], [], \"Modelo no disponible\"\n",
    "\n",
    "    breed_counts = Counter(similar_labels)\n",
    "    predicted_breed = breed_counts.most_common(1)[0][0]\n",
    "\n",
    "    return similar_images, similar_labels, predicted_breed\n",
    "\n",
    "def gradio_search(image, model_name):\n",
    "    if image is None:\n",
    "        return \"Por favor sube una imagen\", []\n",
    "\n",
    "    try:\n",
    "        similar_images, similar_labels, predicted_breed = search_similar_images(image, model_name, k=10)\n",
    "\n",
    "        if isinstance(predicted_breed, str) and predicted_breed.startswith(\"Error\"):\n",
    "            return predicted_breed, []\n",
    "\n",
    "        result_text = f\"Modelo: {model_name}\\nRaza predicha: {predicted_breed}\"\n",
    "\n",
    "        gallery_images = []\n",
    "        for img_path, label in zip(similar_images, similar_labels):\n",
    "            gallery_images.append((img_path, label))\n",
    "\n",
    "        return result_text, gallery_images\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\", []\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Etapa 2: Buscador con Selector de Modelos\")\n",
    "    gr.Markdown(\"Compara el rendimiento de diferentes modelos de extraccion de caracteristicas\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            input_image = gr.Image(type=\"filepath\", label=\"Subir imagen\")\n",
    "\n",
    "            model_selector = gr.Radio(\n",
    "                choices=[\"ResNet50 (Pre-entrenado)\", \"ResNet18 (Fine-tuned)\"],\n",
    "                value=\"ResNet50 (Pre-entrenado)\",\n",
    "                label=\"Seleccionar Modelo\"\n",
    "            )\n",
    "\n",
    "            search_btn = gr.Button(\"Buscar\")\n",
    "\n",
    "        with gr.Column():\n",
    "            result_text = gr.Textbox(label=\"Resultado\", lines=3)\n",
    "\n",
    "    gallery = gr.Gallery(label=\"Imagenes similares\", columns=5)\n",
    "\n",
    "    search_btn.click(\n",
    "        gradio_search,\n",
    "        inputs=[input_image, model_selector],\n",
    "        outputs=[result_text, gallery]\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nLanzando aplicacion Gradio - Etapa 2...\")\n",
    "    dataset_path = os.path.abspath('dataset')\n",
    "    demo.launch(\n",
    "        share=False,\n",
    "        server_name=\"127.0.0.1\",\n",
    "        server_port=7860,\n",
    "        allowed_paths=[dataset_path]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 3: Detección y Clasificación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluar_pipeline.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando: {device}\")\n",
    "\n",
    "transform = get_val_transform()\n",
    "\n",
    "print(\"Cargando modelos...\")\n",
    "\n",
    "yolo_model = YOLO('yolov8n.pt')\n",
    "print(\"YOLO preentrenado cargado (clase 'dog' = 16 en COCO)\")\n",
    "\n",
    "csv_file = 'dataset/dogs.csv'\n",
    "test_dataset = DogDataset(csv_file, 'dataset', 'test', transform=transform)\n",
    "num_classes = test_dataset.num_classes\n",
    "\n",
    "classifier = get_resnet18(num_classes, pretrained=False)\n",
    "classifier.load_state_dict(torch.load('etapa-2/resnet18_best.pth', map_location=device))\n",
    "classifier = classifier.to(device)\n",
    "classifier.eval()\n",
    "\n",
    "print(f\"\\nEvaluando pipeline en {len(test_dataset)} imagenes de test...\")\n",
    "\n",
    "total_images = 0\n",
    "detected_images = 0\n",
    "correct_classifications = 0\n",
    "detection_confidences = []\n",
    "classification_confidences = []\n",
    "\n",
    "all_true_labels = []\n",
    "all_pred_labels = []\n",
    "\n",
    "for idx in tqdm(range(len(test_dataset))):\n",
    "    img_tensor, true_label, img_path = test_dataset[idx]\n",
    "\n",
    "    pil_image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "    results = yolo_model(pil_image, conf=0.25, verbose=False)\n",
    "\n",
    "    dog_detected = False\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            cls = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "\n",
    "            if cls == 16:\n",
    "                dog_detected = True\n",
    "                detection_confidences.append(conf)\n",
    "\n",
    "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                dog_crop = pil_image.crop((x1, y1, x2, y2))\n",
    "\n",
    "                if dog_crop.width < 10 or dog_crop.height < 10:\n",
    "                    continue\n",
    "\n",
    "                img_tensor_crop = transform(dog_crop).unsqueeze(0).to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = classifier(img_tensor_crop)\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    predicted_idx = predicted.item()\n",
    "\n",
    "                    probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                    conf_class = probabilities[0][predicted_idx].item()\n",
    "                    classification_confidences.append(conf_class)\n",
    "\n",
    "                all_true_labels.append(true_label)\n",
    "                all_pred_labels.append(predicted_idx)\n",
    "\n",
    "                if predicted_idx == true_label:\n",
    "                    correct_classifications += 1\n",
    "\n",
    "                break\n",
    "\n",
    "        if dog_detected:\n",
    "            break\n",
    "\n",
    "    total_images += 1\n",
    "    if dog_detected:\n",
    "        detected_images += 1\n",
    "\n",
    "detection_rate = 100. * detected_images / total_images\n",
    "classification_acc = 100. * correct_classifications / detected_images if detected_images > 0 else 0\n",
    "avg_detection_conf = np.mean(detection_confidences) if detection_confidences else 0\n",
    "avg_classification_conf = np.mean(classification_confidences) if classification_confidences else 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTADOS DEL PIPELINE COMPLETO\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Imagenes procesadas:           {total_images}\")\n",
    "print(f\"Perros detectados:             {detected_images} ({detection_rate:.2f}%)\")\n",
    "print(f\"Clasificaciones correctas:     {correct_classifications}\")\n",
    "print(f\"Accuracy de clasificacion:     {classification_acc:.2f}%\")\n",
    "print(f\"Confianza promedio deteccion:  {avg_detection_conf:.4f}\")\n",
    "print(f\"Confianza promedio clasificacion: {avg_classification_conf:.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "if len(all_true_labels) > 0:\n",
    "    unique_labels = np.unique(np.concatenate([all_true_labels, all_pred_labels]))\n",
    "    target_names = [test_dataset.idx_to_label[i] for i in unique_labels]\n",
    "\n",
    "    report = classification_report(\n",
    "        all_true_labels,\n",
    "        all_pred_labels,\n",
    "        labels=unique_labels,\n",
    "        target_names=target_names,\n",
    "        output_dict=True,\n",
    "        zero_division=0\n",
    "    )\n",
    "\n",
    "    print(\"\\nMETRICAS GLOBALES:\")\n",
    "    print(f\"Accuracy:        {report['accuracy']:.4f}\")\n",
    "    print(f\"Macro Avg F1:    {report['macro avg']['f1-score']:.4f}\")\n",
    "    print(f\"Weighted Avg F1: {report['weighted avg']['f1-score']:.4f}\")\n",
    "\n",
    "    metrics_df = pd.DataFrame(report).transpose()\n",
    "    metrics_df.to_csv('metricas_pipeline.csv')\n",
    "    print(\"\\nMetricas guardadas en metricas_pipeline.csv\")\n",
    "\n",
    "print(\"\\nEvaluacion completada!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### app_deteccion.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando: {device}\")\n",
    "\n",
    "transform = get_val_transform()\n",
    "\n",
    "print(\"Cargando YOLO preentrenado...\")\n",
    "yolo_model = YOLO('yolov8n.pt')\n",
    "print(\"YOLO cargado (clase 'dog' = 16 en COCO)\")\n",
    "\n",
    "print(\"Cargando clasificador ResNet18...\")\n",
    "csv_file = 'dataset/dogs.csv'\n",
    "temp_dataset = DogDataset(csv_file, 'dataset', 'train', transform=transform)\n",
    "num_classes = temp_dataset.num_classes\n",
    "\n",
    "classifier = get_resnet18(num_classes, pretrained=False)\n",
    "classifier_path = 'etapa-2/resnet18_best.pth'\n",
    "if os.path.exists(classifier_path):\n",
    "    classifier.load_state_dict(torch.load(classifier_path, map_location=device))\n",
    "    classifier = classifier.to(device)\n",
    "    classifier.eval()\n",
    "    print(\"Clasificador ResNet18 cargado\")\n",
    "else:\n",
    "    classifier = None\n",
    "    print(\"ERROR: ResNet18 no encontrado. Ejecuta 'python entrenar_resnet18.py' en etapa-2\")\n",
    "\n",
    "def detect_and_classify(image):\n",
    "    if classifier is None:\n",
    "        return None, \"Error: Clasificador no encontrado\"\n",
    "\n",
    "    if isinstance(image, np.ndarray):\n",
    "        pil_image = Image.fromarray(image)\n",
    "    else:\n",
    "        pil_image = image\n",
    "\n",
    "    results = yolo_model(pil_image, conf=0.25)\n",
    "\n",
    "    detections = []\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            cls = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "\n",
    "            if cls == 16:\n",
    "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                detections.append({\n",
    "                    'box': (int(x1), int(y1), int(x2), int(y2)),\n",
    "                    'confidence': conf\n",
    "                })\n",
    "\n",
    "    if len(detections) == 0:\n",
    "        return pil_image, \"No se detectaron perros en la imagen\"\n",
    "\n",
    "    output_image = pil_image.copy()\n",
    "    draw = ImageDraw.Draw(output_image)\n",
    "\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/System/Library/Fonts/Helvetica.ttc\", 20)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    results_text = f\"Detectados {len(detections)} perro(s):\\n\\n\"\n",
    "\n",
    "    for i, detection in enumerate(detections):\n",
    "        x1, y1, x2, y2 = detection['box']\n",
    "        conf = detection['confidence']\n",
    "\n",
    "        dog_crop = pil_image.crop((x1, y1, x2, y2))\n",
    "\n",
    "        if dog_crop.width < 10 or dog_crop.height < 10:\n",
    "            continue\n",
    "\n",
    "        img_tensor = transform(dog_crop).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = classifier(img_tensor)\n",
    "            _, predicted = outputs.max(1)\n",
    "            predicted_idx = predicted.item()\n",
    "\n",
    "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            confidence = probabilities[0][predicted_idx].item()\n",
    "\n",
    "            breed = temp_dataset.idx_to_label[predicted_idx]\n",
    "\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=\"green\", width=3)\n",
    "\n",
    "        label = f\"{breed} ({confidence*100:.1f}%)\"\n",
    "\n",
    "        bbox = draw.textbbox((x1, y1-25), label, font=font)\n",
    "        draw.rectangle(bbox, fill=\"green\")\n",
    "        draw.text((x1, y1-25), label, fill=\"white\", font=font)\n",
    "\n",
    "        results_text += f\"Perro {i+1}:\\n\"\n",
    "        results_text += f\"  Raza: {breed}\\n\"\n",
    "        results_text += f\"  Confianza: {confidence*100:.1f}%\\n\"\n",
    "        results_text += f\"  Deteccion: {conf*100:.1f}%\\n\\n\"\n",
    "\n",
    "    return output_image, results_text\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Etapa 3: Deteccion y Clasificacion de Razas de Perros\")\n",
    "    gr.Markdown(\"Pipeline completo: YOLO detecta perros -> ResNet18 clasifica raza\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            input_image = gr.Image(type=\"pil\", label=\"Subir imagen\")\n",
    "            detect_btn = gr.Button(\"Detectar y Clasificar\")\n",
    "\n",
    "        with gr.Column():\n",
    "            output_image = gr.Image(type=\"pil\", label=\"Detecciones\")\n",
    "            result_text = gr.Textbox(label=\"Resultados\", lines=10)\n",
    "\n",
    "    detect_btn.click(\n",
    "        detect_and_classify,\n",
    "        inputs=[input_image],\n",
    "        outputs=[output_image, result_text]\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nLanzando aplicacion Gradio - Etapa 3...\")\n",
    "    demo.launch(\n",
    "        share=False,\n",
    "        server_name=\"127.0.0.1\",\n",
    "        server_port=7861\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa 4: Optimización y Anotación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### anotar_automatico.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando: {device}\")\n",
    "\n",
    "transform = get_val_transform()\n",
    "\n",
    "print(\"Cargando modelos...\")\n",
    "yolo_model = YOLO('yolov8n.pt')\n",
    "\n",
    "csv_file = 'dataset/dogs.csv'\n",
    "temp_dataset = DogDataset(csv_file, 'dataset', 'train', transform=transform)\n",
    "num_classes = temp_dataset.num_classes\n",
    "\n",
    "classifier = get_resnet18(num_classes, pretrained=False)\n",
    "classifier.load_state_dict(torch.load('etapa-2/resnet18_best.pth', map_location=device))\n",
    "classifier = classifier.to(device)\n",
    "classifier.eval()\n",
    "\n",
    "input_folder = \"dataset/test\"\n",
    "input_folder = Path(input_folder)\n",
    "\n",
    "if not input_folder.exists():\n",
    "    print(f\"ERROR: La carpeta {input_folder} no existe\")\n",
    "    sys.exit(1)\n",
    "\n",
    "image_files = list(input_folder.glob(\"*.jpg\")) + list(input_folder.glob(\"*.jpeg\")) + list(input_folder.glob(\"*.png\"))\n",
    "\n",
    "if len(image_files) == 0:\n",
    "    print(\"ERROR: No se encontraron imagenes en la carpeta\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(f\"\\nEncontradas {len(image_files)} imagenes\")\n",
    "\n",
    "output_yolo = Path('anotaciones_yolo')\n",
    "output_yolo.mkdir(exist_ok=True)\n",
    "\n",
    "coco_output = {\n",
    "    'info': {\n",
    "        'description': 'Anotaciones automaticas de perros',\n",
    "        'date_created': datetime.now().isoformat()\n",
    "    },\n",
    "    'images': [],\n",
    "    'annotations': [],\n",
    "    'categories': []\n",
    "}\n",
    "\n",
    "breed_to_category_id = {}\n",
    "category_id_counter = 1\n",
    "\n",
    "for breed in temp_dataset.label_to_idx.keys():\n",
    "    coco_output['categories'].append({\n",
    "        'id': category_id_counter,\n",
    "        'name': breed,\n",
    "        'supercategory': 'dog'\n",
    "    })\n",
    "    breed_to_category_id[breed] = category_id_counter\n",
    "    category_id_counter += 1\n",
    "\n",
    "annotation_id = 1\n",
    "\n",
    "print(\"\\nProcesando imagenes...\")\n",
    "\n",
    "for img_idx, img_path in enumerate(image_files):\n",
    "    print(f\"Procesando {img_idx+1}/{len(image_files)}: {img_path.name}\")\n",
    "\n",
    "    pil_image = Image.open(img_path).convert('RGB')\n",
    "    img_width, img_height = pil_image.size\n",
    "\n",
    "    coco_output['images'].append({\n",
    "        'id': img_idx + 1,\n",
    "        'file_name': img_path.name,\n",
    "        'width': img_width,\n",
    "        'height': img_height\n",
    "    })\n",
    "\n",
    "    results = yolo_model(pil_image, conf=0.25, verbose=False)\n",
    "\n",
    "    yolo_annotations = []\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            cls = int(box.cls[0])\n",
    "            if cls == 16:\n",
    "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                dog_crop = pil_image.crop((x1, y1, x2, y2))\n",
    "                if dog_crop.width < 10 or dog_crop.height < 10:\n",
    "                    continue\n",
    "\n",
    "                img_tensor = transform(dog_crop).unsqueeze(0).to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = classifier(img_tensor)\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    predicted_idx = predicted.item()\n",
    "                    breed = temp_dataset.idx_to_label[predicted_idx]\n",
    "\n",
    "                x_center = ((x1 + x2) / 2) / img_width\n",
    "                y_center = ((y1 + y2) / 2) / img_height\n",
    "                width = (x2 - x1) / img_width\n",
    "                height = (y2 - y1) / img_height\n",
    "\n",
    "                class_id = predicted_idx\n",
    "                yolo_annotations.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
    "\n",
    "                coco_bbox = [x1, y1, x2 - x1, y2 - y1]\n",
    "                coco_output['annotations'].append({\n",
    "                    'id': annotation_id,\n",
    "                    'image_id': img_idx + 1,\n",
    "                    'category_id': breed_to_category_id[breed],\n",
    "                    'bbox': coco_bbox,\n",
    "                    'area': (x2 - x1) * (y2 - y1),\n",
    "                    'iscrowd': 0\n",
    "                })\n",
    "                annotation_id += 1\n",
    "\n",
    "    yolo_file = output_yolo / f\"{img_path.stem}.txt\"\n",
    "    with open(yolo_file, 'w') as f:\n",
    "        f.write('\\n'.join(yolo_annotations))\n",
    "\n",
    "print(f\"\\nAnotaciones YOLO guardadas en: {output_yolo}/\")\n",
    "\n",
    "coco_file = 'anotaciones_coco.json'\n",
    "with open(coco_file, 'w') as f:\n",
    "    json.dump(coco_output, f, indent=2)\n",
    "\n",
    "print(f\"Anotaciones COCO guardadas en: {coco_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Imagenes procesadas:       {len(image_files)}\")\n",
    "print(f\"Total de anotaciones:      {annotation_id - 1}\")\n",
    "print(f\"Clases detectadas:         {len(set([ann['category_id'] for ann in coco_output['annotations']]))}\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nFormatos generados:\")\n",
    "print(f\"  - YOLOv5 (.txt):         {output_yolo}/\")\n",
    "print(f\"  - COCO (.json):          {coco_file}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### herramienta_anotar.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Esta herramienta requiere interfaz gráfica local y no puede ejecutarse en Colab.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimizar_modelos.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "print(f\"Usando CPU para cuantizacion\")\n",
    "\n",
    "print(\"\\nCargando modelo ResNet18 original...\")\n",
    "csv_file = 'dataset/dogs.csv'\n",
    "test_dataset = DogDataset(csv_file, 'dataset', 'test', transform=get_val_transform())\n",
    "num_classes = test_dataset.num_classes\n",
    "\n",
    "model_original = get_resnet18(num_classes, pretrained=False)\n",
    "model_original.load_state_dict(torch.load('etapa-2/resnet18_best.pth', map_location=device))\n",
    "model_original = model_original.to(device)\n",
    "model_original.eval()\n",
    "\n",
    "print(\"Creando modelo cuantizado...\")\n",
    "model_quantized = get_resnet18(num_classes, pretrained=False)\n",
    "model_quantized.load_state_dict(torch.load('etapa-2/resnet18_best.pth', map_location=device))\n",
    "model_quantized = model_quantized.to(device)\n",
    "model_quantized.eval()\n",
    "\n",
    "model_quantized.qconfig = torch.quantization.get_default_qconfig('x86')\n",
    "model_quantized_prepared = torch.quantization.prepare(model_quantized, inplace=False)\n",
    "\n",
    "print(\"Calibrando modelo con datos de validacion...\")\n",
    "val_dataset = DogDataset(csv_file, 'dataset', 'valid', transform=get_val_transform())\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (images, labels, _) in enumerate(val_loader):\n",
    "        if i >= 5:\n",
    "            break\n",
    "        images = images.to(device)\n",
    "        model_quantized_prepared(images)\n",
    "\n",
    "print(\"Convirtiendo a modelo cuantizado...\")\n",
    "model_quantized_final = torch.quantization.convert(model_quantized_prepared, inplace=False)\n",
    "\n",
    "print(\"Guardando modelo cuantizado...\")\n",
    "torch.save(model_quantized_final.state_dict(), 'resnet18_quantized.pth')\n",
    "print(\"Modelo cuantizado guardado en resnet18_quantized.pth\")\n",
    "\n",
    "print(\"\\nEvaluando modelo original...\")\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "def evaluate_model(model, loader, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    inference_times = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            start_time = time.time()\n",
    "            outputs = model(images)\n",
    "            inference_time = time.time() - start_time\n",
    "            inference_times.append(inference_time)\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    accuracy = 100. * correct / total\n",
    "    avg_inference_time = np.mean(inference_times) * 1000\n",
    "    return accuracy, avg_inference_time\n",
    "\n",
    "acc_original, time_original = evaluate_model(model_original, test_loader, device)\n",
    "print(f\"Accuracy: {acc_original:.2f}%\")\n",
    "print(f\"Tiempo promedio de inferencia: {time_original:.2f}ms por batch\")\n",
    "\n",
    "print(\"\\nEvaluando modelo cuantizado...\")\n",
    "acc_quantized, time_quantized = evaluate_model(model_quantized_final, test_loader, device)\n",
    "print(f\"Accuracy: {acc_quantized:.2f}%\")\n",
    "print(f\"Tiempo promedio de inferencia: {time_quantized:.2f}ms por batch\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARACION DE MODELOS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Metrica':<30} {'Original':<20} {'Cuantizado':<20} {'Diferencia':<15}\")\n",
    "print(\"-\"*80)\n",
    "print(f\"{'Accuracy (%)':<30} {acc_original:<20.2f} {acc_quantized:<20.2f} {acc_quantized - acc_original:<15.2f}\")\n",
    "print(f\"{'Tiempo (ms/batch)':<30} {time_original:<20.2f} {time_quantized:<20.2f} {time_quantized - time_original:<15.2f}\")\n",
    "print(f\"{'Speedup':<30} {'-':<20} {time_original/time_quantized:<20.2f}x {'-':<15}\")\n",
    "\n",
    "size_original = os.path.getsize('etapa-2/resnet18_best.pth') / (1024 * 1024)\n",
    "size_quantized = os.path.getsize('resnet18_quantized.pth') / (1024 * 1024)\n",
    "print(f\"{'Tamano (MB)':<30} {size_original:<20.2f} {size_quantized:<20.2f} {size_quantized - size_original:<15.2f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = {\n",
    "    'original': {\n",
    "        'accuracy': float(acc_original),\n",
    "        'inference_time_ms': float(time_original),\n",
    "        'size_mb': float(size_original)\n",
    "    },\n",
    "    'quantized': {\n",
    "        'accuracy': float(acc_quantized),\n",
    "        'inference_time_ms': float(time_quantized),\n",
    "        'size_mb': float(size_quantized),\n",
    "        'speedup': float(time_original / time_quantized)\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('resultados_optimizacion.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"\\nResultados guardados en resultados_optimizacion.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluar_pipeline.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando: {device}\")\n",
    "\n",
    "transform = get_val_transform()\n",
    "\n",
    "print(\"Cargando modelos...\")\n",
    "yolo_model = YOLO('yolov8n.pt')\n",
    "\n",
    "csv_file = 'dataset/dogs.csv'\n",
    "temp_dataset = DogDataset(csv_file, 'dataset', 'train', transform=transform)\n",
    "num_classes = temp_dataset.num_classes\n",
    "\n",
    "classifier = get_resnet18(num_classes, pretrained=False)\n",
    "classifier.load_state_dict(torch.load('etapa-2/resnet18_best.pth', map_location=device))\n",
    "classifier = classifier.to(device)\n",
    "classifier.eval()\n",
    "\n",
    "print(\"\\nCargando anotaciones manuales...\")\n",
    "annotations_file = 'anotaciones_manuales.json'\n",
    "\n",
    "if not os.path.exists(annotations_file):\n",
    "    print(f\"\\nERROR: No se encontro {annotations_file}\")\n",
    "    print(\"Por favor crea el archivo con las anotaciones manuales de 10 imagenes complejas.\")\n",
    "    print(\"Formato esperado:\")\n",
    "    print(\"\"\"\n",
    "{\n",
    "  \"images\": [\n",
    "    {\n",
    "      \"file\": \"ruta/imagen1.jpg\",\n",
    "      \"annotations\": [\n",
    "        {\n",
    "          \"bbox\": [x1, y1, x2, y2],\n",
    "          \"breed\": \"nombre_raza\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "    \"\"\")\n",
    "    sys.exit(1)\n",
    "\n",
    "with open(annotations_file, 'r') as f:\n",
    "    ground_truth = json.load(f)\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    x1_min, y1_min, x1_max, y1_max = box1\n",
    "    x2_min, y2_min, x2_max, y2_max = box2\n",
    "\n",
    "    inter_x_min = max(x1_min, x2_min)\n",
    "    inter_y_min = max(y1_min, y2_min)\n",
    "    inter_x_max = min(x1_max, x2_max)\n",
    "    inter_y_max = min(y1_max, y2_max)\n",
    "\n",
    "    if inter_x_max < inter_x_min or inter_y_max < inter_y_min:\n",
    "        return 0.0\n",
    "\n",
    "    inter_area = (inter_x_max - inter_x_min) * (inter_y_max - inter_y_min)\n",
    "    box1_area = (x1_max - x1_min) * (y1_max - y1_min)\n",
    "    box2_area = (x2_max - x2_min) * (y2_max - y2_min)\n",
    "\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "    return inter_area / union_area if union_area > 0 else 0.0\n",
    "\n",
    "print(\"\\nEvaluando pipeline en imagenes anotadas manualmente...\")\n",
    "\n",
    "total_gt_boxes = 0\n",
    "total_pred_boxes = 0\n",
    "true_positives = 0\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "\n",
    "iou_threshold = 0.5\n",
    "ious = []\n",
    "classification_correct = 0\n",
    "classification_total = 0\n",
    "\n",
    "for image_data in ground_truth['images']:\n",
    "    img_path = image_data['file']\n",
    "    gt_annotations = image_data['annotations']\n",
    "\n",
    "    total_gt_boxes += len(gt_annotations)\n",
    "\n",
    "    pil_image = Image.open(img_path).convert('RGB')\n",
    "    results = yolo_model(pil_image, conf=0.25, verbose=False)\n",
    "\n",
    "    pred_boxes = []\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            cls = int(box.cls[0])\n",
    "            if cls == 16:\n",
    "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                conf = float(box.conf[0])\n",
    "\n",
    "                dog_crop = pil_image.crop((int(x1), int(y1), int(x2), int(y2)))\n",
    "                if dog_crop.width < 10 or dog_crop.height < 10:\n",
    "                    continue\n",
    "\n",
    "                img_tensor = transform(dog_crop).unsqueeze(0).to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = classifier(img_tensor)\n",
    "                    _, predicted = outputs.max(1)\n",
    "                    predicted_idx = predicted.item()\n",
    "                    breed = temp_dataset.idx_to_label[predicted_idx]\n",
    "\n",
    "                pred_boxes.append({\n",
    "                    'bbox': [int(x1), int(y1), int(x2), int(y2)],\n",
    "                    'breed': breed,\n",
    "                    'conf': conf,\n",
    "                    'matched': False\n",
    "                })\n",
    "\n",
    "    total_pred_boxes += len(pred_boxes)\n",
    "\n",
    "    for gt_ann in gt_annotations:\n",
    "        gt_box = gt_ann['bbox']\n",
    "        gt_breed = gt_ann['breed']\n",
    "        best_iou = 0.0\n",
    "        best_match = None\n",
    "\n",
    "        for pred in pred_boxes:\n",
    "            if pred['matched']:\n",
    "                continue\n",
    "\n",
    "            iou = calculate_iou(gt_box, pred['bbox'])\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_match = pred\n",
    "\n",
    "        if best_iou >= iou_threshold and best_match is not None:\n",
    "            true_positives += 1\n",
    "            best_match['matched'] = True\n",
    "            ious.append(best_iou)\n",
    "\n",
    "            if best_match['breed'] == gt_breed:\n",
    "                classification_correct += 1\n",
    "            classification_total += 1\n",
    "        else:\n",
    "            false_negatives += 1\n",
    "\n",
    "    for pred in pred_boxes:\n",
    "        if not pred['matched']:\n",
    "            false_positives += 1\n",
    "\n",
    "precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "avg_iou = np.mean(ious) if ious else 0\n",
    "classification_acc = classification_correct / classification_total if classification_total > 0 else 0\n",
    "\n",
    "def calculate_ap(precisions, recalls):\n",
    "    precisions = np.array([0] + precisions + [0])\n",
    "    recalls = np.array([0] + recalls + [1])\n",
    "\n",
    "    for i in range(len(precisions) - 2, -1, -1):\n",
    "        precisions[i] = max(precisions[i], precisions[i + 1])\n",
    "\n",
    "    indices = np.where(recalls[1:] != recalls[:-1])[0] + 1\n",
    "    ap = np.sum((recalls[indices] - recalls[indices - 1]) * precisions[indices])\n",
    "    return ap\n",
    "\n",
    "all_predictions = []\n",
    "for image_data in ground_truth['images']:\n",
    "    img_path = image_data['file']\n",
    "    pil_image = Image.open(img_path).convert('RGB')\n",
    "    results = yolo_model(pil_image, conf=0.25, verbose=False)\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            cls = int(box.cls[0])\n",
    "            if cls == 16:\n",
    "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                conf = float(box.conf[0])\n",
    "                all_predictions.append((conf, img_path, [int(x1), int(y1), int(x2), int(y2)]))\n",
    "\n",
    "all_predictions.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "tp_list = []\n",
    "fp_list = []\n",
    "for conf, img_path, pred_box in all_predictions:\n",
    "    img_data = next((img for img in ground_truth['images'] if img['file'] == img_path), None)\n",
    "    if img_data is None:\n",
    "        fp_list.append(1)\n",
    "        tp_list.append(0)\n",
    "        continue\n",
    "\n",
    "    matched = False\n",
    "    for gt_ann in img_data['annotations']:\n",
    "        iou = calculate_iou(gt_ann['bbox'], pred_box)\n",
    "        if iou >= iou_threshold:\n",
    "            matched = True\n",
    "            break\n",
    "\n",
    "    if matched:\n",
    "        tp_list.append(1)\n",
    "        fp_list.append(0)\n",
    "    else:\n",
    "        tp_list.append(0)\n",
    "        fp_list.append(1)\n",
    "\n",
    "tp_cumsum = np.cumsum(tp_list)\n",
    "fp_cumsum = np.cumsum(fp_list)\n",
    "\n",
    "precisions_curve = tp_cumsum / (tp_cumsum + fp_cumsum + 1e-10)\n",
    "recalls_curve = tp_cumsum / total_gt_boxes if total_gt_boxes > 0 else np.zeros_like(tp_cumsum)\n",
    "\n",
    "ap = calculate_ap(precisions_curve.tolist(), recalls_curve.tolist())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTADOS DE EVALUACION DEL PIPELINE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Imagenes evaluadas:              {len(ground_truth['images'])}\")\n",
    "print(f\"Total GT boxes:                  {total_gt_boxes}\")\n",
    "print(f\"Total predicciones:              {total_pred_boxes}\")\n",
    "print(f\"True Positives:                  {true_positives}\")\n",
    "print(f\"False Positives:                 {false_positives}\")\n",
    "print(f\"False Negatives:                 {false_negatives}\")\n",
    "print(f\"\\nPrecision:                       {precision:.4f}\")\n",
    "print(f\"Recall:                          {recall:.4f}\")\n",
    "print(f\"F1-Score:                        {f1_score:.4f}\")\n",
    "print(f\"Average IoU:                     {avg_iou:.4f}\")\n",
    "print(f\"mAP@0.5:                         {ap:.4f}\")\n",
    "print(f\"\\nClassification Accuracy:         {classification_acc:.4f} ({classification_correct}/{classification_total})\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results_dict = {\n",
    "    'num_images': len(ground_truth['images']),\n",
    "    'total_gt_boxes': total_gt_boxes,\n",
    "    'total_predictions': total_pred_boxes,\n",
    "    'true_positives': true_positives,\n",
    "    'false_positives': false_positives,\n",
    "    'false_negatives': false_negatives,\n",
    "    'precision': float(precision),\n",
    "    'recall': float(recall),\n",
    "    'f1_score': float(f1_score),\n",
    "    'average_iou': float(avg_iou),\n",
    "    'mAP@0.5': float(ap),\n",
    "    'classification_accuracy': float(classification_acc)\n",
    "}\n",
    "\n",
    "with open('resultados_evaluacion.json', 'w') as f:\n",
    "    json.dump(results_dict, f, indent=2)\n",
    "\n",
    "print(\"\\nResultados guardados en resultados_evaluacion.json\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
